BCAI Conversation API

Swagger provides a user interface for interacting with the API
POST /bcai-public-api/conversation
Method to post a conversation to different models brokered by the Boeing Conversational AI API. Note the response returned is a streaming response.
To explore the schema in detail, or to see more examples:
Visit the BCAI API Swagger
Click /bcai-public-api/conversation
Click either Example Value or Schema
Parameters
model: Toggles between different models. See the BCAI Security API for a list of valid models and their descriptions.
messages: Contains the full conversation history as a list of messages. Each message has a role and content. Acceptable roles include:
system: A system message provides instructions that define the model’s role, personality, or operational boundaries. It usually appears as the first message in the list. If no system message is provided, BCAI applies a default system prompt that sets its persona and behavior. Providing a custom system message overrides this default. To explicitly have no system message, include a blank system message.
user: Represents input from the user — the prompts or questions posed to the model.
assistant: Represents responses generated by the model (the LLM). Including these messages helps maintain conversation context when sending follow-up requests.
response_max_tokens: Optional. | An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and reasoning tokens. Default depends on selected model.
conversation_mode: Toggles between different conversation modes (RAG, standard LLM interaction)
Default value: non-rag. A conversation with the model, not enhanced by any internal Boeing data sources.
Optional value: Name of the RAG you wish to enhance your conversation with. See the endpoint /rags for a current list of RAGs you are authorized to use.
temperature: Optional. Default: 0. | What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.
top_p: Optional. Default: 1 | An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.
stop: Optional. | Not supported with latest reasoning models o3 and o4-mini. Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
response_format: Optional. | An object specifying the format that the model must output. Setting to { "type": "json_schema", "json_schema": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide. Setting to { "type": "json_object" } enables the older JSON mode, which ensures the message the model generates is valid JSON. Using json_schema is preferred for models that support it.
frequency-penalty: Optional. | Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model’s likelihood to repeat the same line verbatim.
presence_penalty: Optional. | Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model’s likelihood to talk about new topics.
seed: Optional. | This feature is in Preview. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism isn’t guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend.
tools: Optional. | A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.
tool_choice: Optional. | Controls which (if any) tool is called by the model. none means the model won’t call any tool and instead generates a message. auto means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools. Specifying a particular tool via {"type": "function", "function": {"name": "my_function"}} forces the model to call that tool. none is the default when no tools are present. auto is the default if tools are present.
parallel_tool_calls: Optional. Default: true | Whether to enable parallel function calling during tool use.
stream: Default: true | If set to false, will disable streaming for the response.
conversation_source: Optional. | System identifier for the API caller’s use case - for example, if inSite were to call BCAI via API, inSite would choose an identifier like bcai-api-inSite.
skip_db_save: Default: true If true, conversation is not saved to the BCAI database.
conversation_guid: Optional. | A unique identifier for your distinct conversations. Used to save and track conversation history when skip_db_save is false.
prompt_id: Optional. | Used by the BCAI API to track conversations when skip_db_save is false.
conversation_name: Optional. | The name of the conversation. Used when skip_db_save is false.
Usage
HTTP Verb: POST
HTTP Headers:
accept: application/json
Content-Type: application/json
Request Examples
Sample Input:
Sample Output [json]:
  {
    "id": "chatcmpl-CBiVZcSHatfRgKxiwtM5jTK6MBj2a",
    "model": "gpt-4.1-mini-2025-04-14",
    "created": 1756908733,
    "object": "chat.completion.chunk",
    "choices": [
      {
        "finish_reason": "stop",
        "messages": [
          {
            "role": "assistant",
            "content": "Hello! How can I be of assistance?"
          }
        ]
      }
    ],
    "usage": {
      "prompt_tokens": 111,
      "completion_tokens": 97,
      "total_tokens": 208
    }
  }
 
Usage Example
        curl       
        Python       
        Java       
        JavaScript       
curl -X 'POST' \'https://bcai-test.web.boeing.com/bcai-public-api/conversation' \ -H 'accept: application/json' \ -H "Authorization: basic <UDAL_PAT>" \ -H 'Content-Type: application/json' \ -d '{
  "messages": [
    {
      "role": "system",
      "content": "here is a system prompt"
    },
    {
      "role": "user",
      "content": "here is a user prompt"
    }
    ],
    "conversation_mode": ["non-rag"],
    "model": "gpt-4o-mini",
    "conversation_guid": "asdf123",
    "conversation_source": "my-system-identifier-name"
}'
 
Usage Example: Image Attachments
        curl       
curl -X 'POST' \'https://bcai-test.web.boeing.com/bcai-public-api/conversation' \ -H 'accept: application/json' \ -H "Authorization: basic <UDAL_PAT>" \ -H 'Content-Type: application/json' \ -d '{
  "messages": [
    {
      "role": "system",
      "content": "here is a picture. describe it for me"
    },
    {
      "role": "user",
      "content": [
        {
          "type": "image_url",
          "image_url": {
            "detail": "low",
            "url": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACkAAAAwCAIAAAAD28TyAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAASdEVYdFNvZnR3YXJlAEdyZWVuc2hvdF5VCAUAAAGHSURBVFhH7Ze9SgNBFIVjY7DzEXwEHyGP4iP4CJaBCCltJFqIrZWdYGO3JmJUCDZBQfAnoAiCleuBe9k53GF/AjObZg5fMTtzZz/uJLuwnXx1Se72k9ztx7lP7hfrg3GnnwWnO7g+vluohuLckcQC9KqhOLepDo5qKMltSoOjGkpym1Jm53y+d/VSwe7F8+ZwYnYZVEOpd0OsFZU5e/w0Gw1aR6l3oy2sorPe6ayMm7efy6dvs9EgFk5TNwQ4VfYJWwdT1EAc1w2kkoNV1ER3o0WMDZhHTXS3mWe2Rw/ATBrEwlnCjbtLf0269BELJ4zbn/ERCyfMmcd1H00/MGCwVPz75l+/QMby1PmIhdPU7QdLOAy9oJSdkC5TlugbN2WwVLxt8F4DMi57sYuF08gNsZk0xPq9ax9cMMxegZk0qIZS7w6FaijJbUqDoxpKcpvSsKz1sz/1uDg3PtfMhoBs7I9VQ3FufKbG0KNjiA9v31VDce5I8Y+6SHR3RZK7/SR3+1mdO8//Acpu9dTf6vNBAAAAAElFTkSuQmCC"
          }
        }
      ]
    }
  ],
  "conversation_mode": ["non-rag"],
  "model": "gpt-4o-mini",
  "conversation_guid": "asdf123",
  "conversation_source": "bcai-api-system-identifier"
}'
 
Usage Example: Structured Outputs with response_format
        curl       
curl -X 'POST' \'https://bcai-test.web.boeing.com/bcai-public-api/conversation' \ -H 'accept: application/json' \ -H "Authorization: basic <UDAL_PAT>" \ -H 'Content-Type: application/json' \ -d '{
    "model": "gpt-4.1-mini",
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "Schedule a meeting between Jon and Ana on August 21st."
          }
        ]
      }
    ],
    "temperature": 0,
    "response_max_tokens": 1500,
    "top_p": 1,
    "stop": "END",
    "response_format": {
        "type": "json_schema",
        "json_schema": {
          "name": "CalendarEventResponse",
          "strict": true,
          "schema": {
            "type": "object",
            "properties": {
              "name": {
                "type": "string"
              },
              "date": {
                "type": "string"
              },
              "participants": {
                "type": "array",
                "items": {
                  "type": "string"
                }
              }
            },
            "required": ["name", "date", "participants"],
            "additionalProperties": false
          }
        }
      },
    "frequency_penalty": 1,
    "presence_penalty": 1,
    "seed": 42,
    "conversation_mode": [
      "non-rag"
    ],
    "conversation_guid": "abc123",
    "conversation_name": "",
    "conversation_source": "bcai-api-docs",
    "prompt_id": 0,
    "skip_db_save": true,
    "stream": false
  }'
 
Usage Example: Tool Calling with tools
        curl       
curl -X 'POST' \'https://bcai-test.web.boeing.com/bcai-public-api/conversation' \ -H 'accept: application/json' \ -H "Authorization: basic <UDAL_PAT>" \ -H 'Content-Type: application/json' \ -d '{
    "model": "gpt-4.1-mini",
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "Please give me the current time in San Francisco, New York City, and London."
          }
        ]
      }
    ],
    "conversation_mode": ["non-rag"],
    "conversation_guid": "abc123",
    "conversation_source": "bcai_documentation",
    "skip_db_save": true,
    "stream": false,
    "tools": [
      {
        "type": "function",
        "function": {
          "name": "get_current_time",
          "description": "Get the current time in a given location",
          "parameters": {
            "type": "object",
            "properties": {
              "location": {
                "type": "string",
                "description": "The city name, e.g. San Francisco"
              }
            },
            "required": ["location"]
          }
        }
      }
    ],
    "tool_choice": "auto",
    "parallel_tool_calls": true
  }'
 
POST /bcai-public-api/embedding
Method to create text embeddings of input provided using various available embedding models. The BCAI API currently supports several embedding models, including OpenAI models (text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002) and Tanzu models (all-MiniLM-L6-v2-us-sovereign, nomic-us-sovereign). Note that the request body for this is similar to the Azure OpenAI embedding endpoints, specifically how the input can be a string or array, as well as the manual specification of the dimensionality of the embedding computations.
You can view all available models and their details via the BCAI Security API.
Parameters
Parameter	Type	Required	Description
input	string or array	Yes	The text to embed. Can be a single string or an array of strings. Each string must not exceed the model’s max input tokens (typically 8192 tokens per input for most embedding models). For multiple inputs, the total tokens across all inputs must not exceed
 300,000. Empty strings are not allowed.
model	string	Yes	The ID of the embedding model to use. Examples: "text-embedding-3-small",
"text-embedding-3-large", "text-embedding-ada-002", 
"all-MiniLM-L6-v2-us-sovereign", "nomic-us-sovereign". You can view all available models via the

BCAI Security API.
dimensions	integer	No	The number of dimensions for the output embeddings. Only supported in text-embedding-3 and later models. Example:
1536. If omitted, the model’s default dimensionality is used.
encoding_format	string	No	The format for the returned embeddings. Can be "float" (default) or
"base64". Use "base64" if you need the embeddings encoded as base64 strings.
Notes
Token Limits: Each input string must not exceed the model’s max input tokens (usually 8192). The sum of tokens across all inputs in a single request must not exceed 300,000.
Dimensions: Only certain models (e.g., text-embedding-3-small, text-embedding-3-large) support the dimensions parameter.
Encoding Format: Use "base64" if you need the embeddings in a non-float format (e.g., for transmission/storage).
Model Availability: For a list of available embedding models and their details, use the BCAI Security API.
Usage
HTTP Verb: POST
HTTP Headers:
accept: application/json
Content-Type: application/json
Sample Input:

or (using multiple inputs and overriding the embedding dimensionality)
{
  "input": ["text to embed", "more text to embed"],
  "model": "text-embedding-3-small",
  "dimensions": 100,
  "encoding_format": "base64"
}
 
Sample Output [string]:
For embedding a string:
 {"data": [{"embedding": [0.04767368,0.6931575,0.12311102,0.7036856,0.08324852],"index": 0,"object": "embedding"}],"model": "text-embedding-3-large","object": "list","usage": {"prompt_tokens": 1,"total_tokens": 1}}
 
for embedding a list of strings:
 {"data": [{"embedding": [0.04767368,0.6931575,0.12311102,0.7036856,0.08324852],"index": 0,"object": "embedding"},{"embedding": [0.1372751,0.92268926,-0.2063156,0.16548231,-0.2446416],"index": 1,"object": "embedding"}],"model": "text-embedding-3-large","object": "list","usage": {"prompt_tokens": 3,"total_tokens": 3}}
 
Usage Example
        curl       
        Python       
        Java       
        JavaScript       
curl -X 'POST' \'https://bcai-test.web.boeing.com/bcai-public-api/embedding' \ -H 'accept: application/json' \ -H 'Content-Type: application/json' \ -H 'Authorization: basic <UDAL_PAT>' \ -d '{
"input": "string",
"model": "text-embedding-3-small"
}'
 
Deprecated Endpoints
These endpoints are still functional, but you are encouraged to move to the new endpoints as soon as possible.
Migrate as soon as possible, since these deprected endpoints will be slower than they were previously.
[Deprecated] GET /bcai-public-api/isAuthorized
Moved to GET /bcai-public-security-api/authorized
BCAI Security API Documentation
[Deprecated] GET /bcai-public-api/getModels
Moved to GET /bcai-public-security-api/models
BCAI Security API Documentation
[Deprecated] GET /bcai-public-api/getRags
Moved to GET /bcai-public-security-api/rags
BCAI Security API Documentation
[Deprecated] GET /bcai-public-api/getModelsForDataSource
Moved to GET /bcai-public-security-api/rags-with-models
BCAI Security API Documentation
[Deprecated] POST /bcai-public-api/countTokens
Moved to POST /bcai-public-token-counter-api/count-tokens
BCAI Token Counter API Documentation
Change Log
2025-07-30 INFO Adds additional parameter documentation and example usage for /conversation. Deprecated several endpoints that were moved to new microservices.
2025-02-10 NEW Adds seed parameter as a preview feature for v1/conversation
2024-10-16 NEW Adds additional example usage for /conversation on how to process images
2024-06-05 NEW Adds /embedding endpoint to expose text embedding models
2024-04-11 NEW Adds stream parameter on conversation endpoint to enable/disable streaming per response/request.
2024-03-21 INFO New process for approval for API access and use case registration
2024-03-21 INFO New versioned v1/conversation endpount announcment (coming April 2024)
2024-03-21 DEPRECATION WARNING Unversioned /conversation to be deprecated March 2024
{
  "input": "text to embed",
  "model": "text-embedding-3-small"
}
 
{
  "model": "gpt-4.1-mini",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "Hello!"
        }
      ]
    }
  ],
  "temperature": null,
  "response_max_tokens": null,
  "top_p": null,
  "stop": null,
  "response_format": null,
  "frequency_penalty": null,
  "presence_penalty": null,
  "seed": null,
  "reasoning_effort": null,
  "conversation_mode": [
    "non-rag"
  ],
  "conversation_guid": "abc123",
  "conversation_name": "",
  "conversation_source": "bcai_docs_example",
  "prompt_id": 0,
  "skip_db_save": true,
  "stream": false,
  "tools": null,
  "tool_choice": null,
  "parallel_tool_calls": null
}
 
 