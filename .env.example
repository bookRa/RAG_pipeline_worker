# LLM configuration
# Options: openai, bcai, mock
LLM__PROVIDER=openai
LLM__MODEL=gpt-4o-mini
LLM__TEMPERATURE=0.1
LLM__API_KEY=your-openai-key
OPENAI_API_KEY=your-openai-key

# For BCAI:
# LLM__PROVIDER=bcai
# LLM__MODEL=gpt-4o-mini
# LLM__API_BASE=https://bcai-test.web.boeing.com
# LLM__API_KEY=your-bcai-pat
# LLM__CONVERSATION_MODE=non-rag
# LLM__CONVERSATION_SOURCE=rag-pipeline-worker
# BCAI_API_KEY=your-bcai-pat
# BCAI_API_BASE=https://bcai-test.web.boeing.com

# Embeddings
# Options: openai, bcai, mock
EMBEDDINGS__PROVIDER=openai
EMBEDDINGS__MODEL=text-embedding-3-small

# For BCAI embeddings (uses same credentials as LLM by default):
# EMBEDDINGS__PROVIDER=bcai
# EMBEDDINGS__MODEL=text-embedding-3-small
# EMBEDDINGS__DIMENSIONS=1536

# Chunking defaults
CHUNKING__SPLITTER=sentence
CHUNKING__CHUNK_SIZE=512
CHUNKING__CHUNK_OVERLAP=50
CHUNKING__INCLUDE_IMAGES=true

# Vector store
VECTOR_STORE__DRIVER=llama_index_local
VECTOR_STORE__PERSIST_DIR=artifacts/vector_store

# Prompt files (override if you relocate them)
PROMPTS__PARSING_SYSTEM_PROMPT_PATH=docs/prompts/parsing/system.md
PROMPTS__PARSING_USER_PROMPT_PATH=docs/prompts/parsing/user.md
PROMPTS__CLEANING_SYSTEM_PROMPT_PATH=docs/prompts/cleaning/system.md
PROMPTS__CLEANING_USER_PROMPT_PATH=docs/prompts/cleaning/user.md
PROMPTS__SUMMARY_PROMPT_PATH=docs/prompts/summarization/system.md

# Storage overrides (optional)
INGESTION_STORAGE_DIR=artifacts/ingestion
DOCUMENT_STORAGE_DIR=artifacts/documents
RUN_ARTIFACTS_DIR=artifacts/runs

# Langfuse observability (optional)
ENABLE_LANGFUSE=false
LANGFUSE_PUBLIC_KEY=pk-...
LANGFUSE_SECRET_KEY=sk-...
LANGFUSE_HOST=https://us.cloud.langfuse.com

# DocumentDB configuration
VECTOR_STORE__DRIVER=documentdb
DOCUMENTDB_URI=mongodb://...
DOCUMENTDB_DATABASE=pipeline_db

# Batch processing configuration
BATCH__MAX_CONCURRENT_DOCUMENTS=5
BATCH__MAX_WORKERS_PER_DOCUMENT=4
BATCH__ENABLE_PAGE_PARALLELISM=true
BATCH__ENABLE_DOCUMENT_PARALLELISM=true
BATCH__RATE_LIMIT_REQUESTS_PER_MINUTE=60
BATCH__PIXMAP_PARALLEL_WORKERS=4